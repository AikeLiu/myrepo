Ning Su
I checked a few things. I think it's not a bug specific to skydiving code. I take a problematic case (where I observed Rerr increase under Newtonian steps), and use standard sdpb 2.5.1 to run it.
(1), with beta=0.3, no matter I use prec=448, 1024, 2048, the runs always end up with HPD error after 6 iterations (the P-obj, D-obj, mu, P-step, D-step are exactly the same in all prec cases).
(2), with beta=1 (i.e. only local centering), no matter I use prec=448, 1024, the run can't decrease D-err below 1e-69. For prec=1024, P-err, p-err are ~ 1e-300. For prec=448, P-err ~ 1e-100, p-err ~ 1e-40. But the D-err are the same in prec = 448 and 1024 (i.e. D-err in n-th of prec 448 run matches exactly with the D-err in n-th iteration of the prec 1024 run), indicating by increase prec we can't have D-err ->0. I think it's likely Slater condition might not be satisfied for the dual problem, so we couldn't find precise on-shell solution with Newtonian steps.
I update the draft "Limitation" part. I described the observation of the issue and say it's likely no on-shell solution with strict X, Y>0. I think I am happy with this part now.


balt
  2:20 PM
OK so let me suppose that the D-err indeed remains too large whereas the P/p-errs effectively go to zero. On the dual side we do have one imprecision in the update which is the symmetrization by hand of dY. Could that have affected things? In other words, can we explicitly compute how this symmetrization affects the change in the constraints?
2:20
@Ning Su
 can you please give me a definition of what you mean with the Slater condition? The one I have in mind does not seem to have anything to do with the problem we are seeing.


Ning Su
  2:47 PM
I mean if Slater condition is satisfied, there is a dual solution satisfy dual on-shell condition with strict Y>0 . Numerically it seems D-err can go to arbitrarily small and step=1.  I think the fact D-err doesn't ->0 could mean strict dual solution doesn't exist. Otherwise I just can't imagine why Newtonian step couldn't decrease D-err no matter which precision we choice. Of course it's still possible there is something wrong in the code (could be Y symmetrization. On the other hand, for normal case, Y symmetrization doesn't affect finding of dual solution).
Even if what I said is true (no strict Y>0 dual solution), why that is the case is still not clear. I am not trying to figure that out here. Instead, I was trying to figure out a better statement about the limitation of the skydiving algorithm. I think we have it now : it's generic problem that even can be seen in standard SDPB algorithm, so it's fine if we don't solve it in this skydiving paper. (edited) 


balt
  1:36 AM
The thing is that Slaterâ€™s condition does not involve mu at all. So if it is violated then there should not be a solution even for mu much larger (at the same point in parameter space of course). So if it is violated then D-err cannot be set to zero even using a climbing run with ordinary sdpb (if that were possible).


Ning Su
  1:40 AM
Great idea! Thanks! This is something I can quickly check (whether at larger mu, D-err ->0 still cannot be achieved)


Ning Su
  7:10 AM
Hi balt, I finished the test. The short answer is that D-err can't decreased to zero and it's independent of mu.
The evidence is in ning\test_limitations\note.nb. There is a fresh run without checkpoint. There is no primal/dual jump in the entire run. There are two runs that tried to centering at duality gap ~0.217 with prec=448, 1024. There is a primal dual jump (step=1), but after the dual jump D-err cannot be arbitrarily small (with prec=1024, D-err is around 1e-80). Those behaviors are just like the instability/trivial mix case (where certain component is scaled to zero), and sharply different from the normal cases. So I think what I said is probably true : this SDP is just inherently doesn't satisfy Slater condition for the dual problem. My conclusion is that primal/dual jump doesn't mean Slater condition (i.e. strictly positive solutions to primal/dual constraints), especially for jumps in centering steps. (edited) 


balt
  7:50 AM
OK thanks for testing!
7:51
Marten made another suggestion: maybe something is wrong with the input anyway. You said 5 iterations went fine and then the 6th failed, independently of the precision. But what if e.g. Y is not positive definite already before the 0th iteration? Would we really notice it?


Ning Su
  7:56 AM
What you said is about my test of yesterday. If you check the message above of the new test today, there is a fresh run WITHOUT checkpoint. (edited) 


Ning Su
  8:39 AM
Hi Balt, I agree that the error is independent of precision is strange. I think in general I think HPD just means there is a numerical instability issue. Of course this explanation is a bit not so consistent with the fact that my yesterday's test is independent of precision. For today's test, the precision does change things a bit (for example precision=1024 can decrease D-err a bit more).
My best guess about what happened is the following:
In the problematic case, at all mu, the exact central path solution has zero determinant in X, Y. But perhaps numerically the solver will just try to stay away from the actual solution (perhaps by the log det X term, so Newtonian step increase R at some point and don't decrease D-err any more). And this "repel the solution from central path" procedure has inherent numerical precision requirement and it's depends on mu. For example, at higher mu, perhaps we only need prec=448 to start to observe the repel. But at lower mu, we might need much higher mu. If prec is not high enough, we just saw HPD error. Perhaps in yesterday's test, the mu is already too low (one could imagine maybe required precision is 1000000), so that prec=448 and 1024 is the same as we move toward the central path. (edited) 
8:43
In the old sdpb, there is "stabled dim" column. When there is numerical instability, this number increases (I heard it's a method to stabilize the numerical instability, but I don't understand the detail). In the case of "health SDP" with low precision, this column could increase a bit and then work smoothly. But for inherently bad cases (trivial mixing/instability case), this column just increase exponentially as mu decrease. Perhaps the analogy of this in the new sdpb is that in order for HPD not happen, the precision has to be increase exponentially as mu decrease. (edited) 


balt
  9:32 AM
is it worth checking whether a dual feasible point can be found if you also increase the precision of the input files? or are you already change the precision of the input files whenever you change the precision of sdpb?


Ning Su
  9:36 AM
I thought the input file precision doesn't matter? it's text based, right? (edited) 


balt
  9:58 AM
since the dual error is so small, I was thinking that it might become strictly feasible again if we give it more precise input....
10:00
text based or not, there are still finitely many digits there....







Ning Su
  10:38 AM
I see. You mean perhaps the block precision affect the problem. I used prec=768 to generate blocks and SDPs. I can double check whether that affect things. In general it shouldn't, because our rational approximation has much much less precision than that. Usually it's computational precision matters.





10:41
I think to solve it, one probably should follow this link : https://physics.stackexchange.com/questions/753534/difficulty-solving-conformal-bootstrap-like-crossing-equations-using-semidefinit  . And perhaps should eliminate some y=0 components. But anyway, this will be complicated thing and it's generic to SDPB, not just skydiving.







Ning Su
  3:14 AM
Hi 
@balt
, I realized that the conclusion from those experiments are extremely useful in practice! I go back to check some problematic runs I had in the past and find that in fact one can observe that Slater condition is not satisfied with step=1 (i.e. D-err is not decreased sufficiently) at a relatively early stage --- same as the experiment. For example, my O(3) tiptop Lambda=35 run is already this type. Therefore had I know this test from the beginning, I would already figure out that this setup is doomed to fail in March and no need to keep running it. Same thing for my Ising Lambda=51 run, no need to waste more time on that setup. So basically this "Slater condition test" is something one can easily do at the beginning of the run and if it fails one should deform the setup a bit to solve it. I think I will honestly share those information in the paper with the readers (edited) 







Message dynamic-navigator










